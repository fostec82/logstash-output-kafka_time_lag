input {
    stdin{}
}

filter {

  mutate {
    # add_field => { "[@metadata][metric_measurement_name]"                  => "chris_kafka_aiad2_lag" }
    add_field => {
      "[@metadata][kafka_topic_producer]"              => "kafka_topic_producer"
      "[@metadata][kafka_consumer_group_producer]"     => "kafka_consumer_group_producer_chris"
      "[@metadata][kafka_append_time_producer]"        => "100"
      "[@metadata][logstash_kafka_read_time_producer]" => "200"
      "[@metadata][kafka_topic_aggregate]"             => "kafka_topic_aggregate"
      "[@metadata][kafka_consumer_group_aggregate]"    => "kafka_consumer_group_aggregate"
      "[@metadata][kafka_append_time_aggregate]"       => "300"
    }
  }

  ruby {
    code => 'logstash_kafka_read_time_aggregate = (Time.now.to_f * 1000).to_i
             event.set( "[@metadata][logstash_kafka_read_time_aggregate]", logstash_kafka_read_time_aggregate )'
  }

}
output {

  kafkatimelag{
    kafka_topic_producer              => "%{[@metadata][kafka_topic_producer]}"
    kafka_consumer_group_producer     => "%{[@metadata][kafka_consumer_group_producer]}"
    kafka_append_time_producer        => "%{[@metadata][kafka_append_time_producer]}"
    logstash_kafka_read_time_producer => "%{[@metadata][logstash_kafka_read_time_producer]}"

    kafka_topic_aggregate              => "%{[@metadata][kafka_topic_aggregate]}"
    kafka_consumer_group_aggregate     => "%{[@metadata][kafka_consumer_group_aggregate]}"
    kafka_append_time_aggregate        => "%{[@metadata][kafka_append_time_aggregate]}"
    logstash_kafka_read_time_aggregate => "%{[@metadata][logstash_kafka_read_time_aggregate]}"
  }

  stdout { codec => rubydebug { metadata => true }}
}
